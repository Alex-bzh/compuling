{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb27f0db-cae5-4f6d-8e87-e9ebf37919a2",
   "metadata": {},
   "source": [
    "# L’écart avec l’espérance comme expression de la distance entre vecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413224b2-13bc-4c21-9b95-297596f6dda4",
   "metadata": {},
   "source": [
    "L’idée derrière la notion d’écart avec l’espérance, en traitement automatique du langage, consiste à comparer la fréquence des mots d’un texte avec celles attendues, calculées à partir de corpus de référence. Il serait ainsi possible de déterminer si telle pièce a bien été écrite par Molière ou s’il s’agit plutôt d’une œuvre non assumée de Corneille, si telle autre relève plutôt du tragique ou du comique, ou si un tweet est une anarque ou bien un fait avéré.\n",
    "\n",
    "La méthode retenue appartient au domaine de la statistique. Elle a été proposée par Adam Kilgarriff dans un article intitulé \"Comparing Corpora\" et publié en 2001 dans le [*International Journal of Corpus Linguistics*](https://doi.org/10.1075/ijcl.6.1.05kil). En convoquant le test du $\\chi^2$ qui d’ordinaire permet de vérifier si une variable suit une loi du $\\chi^2$ sous l’hypothèse nulle, il souhaite estimer la distance qui sépare deux vocabulaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5641f8-eef0-4f15-bb6f-bb7d629d3f71",
   "metadata": {},
   "source": [
    "## Le test du $\\chi^2$ d’indépendance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb43a2-8aa9-4fd9-8241-c3cff7f5eaf0",
   "metadata": {},
   "source": [
    "### Des hypothèses statistiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b04f10-6ee2-42a4-ace4-3650ed8ae75a",
   "metadata": {},
   "source": [
    "Communément, un test statistique sert à vérifier qu’une hypothèse est vraie : c’est *l’hypothèse nulle*, notée $H_0$. Dans le cas contraire, *l’hypothèse alternative*, notée $H_1$, est retenue car considérée comme statistiquement significative. Pour juger de la significativité du test, le résultat de l’expérience est confronté à une loi de probabilité avec un seuil de risque $\\alpha$ généralement établi à 0,05 (5 % de risque d’erreur). Si la probabilité d’obtenir une valeur aussi extrême que celle observée, la valeur-p (ou *p-value* en anglais), est inférieure à ce seuil, de fortes présomptions pèsent contre l’hypothèse nulle que l’on vient de tester. À l’inverse, si la valeur-p est supérieure à ce seuil, on conclut simplement à l’échec du test, sans ne rien dire des hypothèses formulées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca40c0-67b7-481d-995c-8ef3e5d6deb9",
   "metadata": {},
   "source": [
    "### Principe du test d’indépendance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139168ae-23c7-4627-9b31-c83bdb920a27",
   "metadata": {},
   "source": [
    "L’une des applications connues du test du $\\chi^2$ intervient dans l’estimation de la liaison entre deux variables qualitatives : soit elles sont indépendantes ($H_0$) soit elles covarient de manière statistiquement significative ($H_1$).\n",
    "\n",
    "Pour parvenir au résultat, la méthode consiste à établir, pour les variables ciblées, la distance entre les valeurs empiriques ($O_{ij}$) et les valeurs théoriques normalement attendues ($E_{ij}$) si elles étaient indépendantes, selon la formule :\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
    "$$\n",
    "\n",
    "La somme obtenue est alors comparée à [la loi du $\\chi^2$](https://fr.wikipedia.org/wiki/Loi_du_%CF%87%C2%B2#Table_de_valeurs_des_quantiles) avec $k$ degrés de liberté pour un risque d’erreur de 5 %, sachant que les degrés de liberté s’obtiennent en effectuant le produit entre le nombre de lignes et le nombre de colonnes selon la formule :\n",
    "\n",
    "$$\n",
    "k = (I – 1)(J – 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2782ff-db2a-4f6f-bdf1-aedc4723bfe4",
   "metadata": {},
   "source": [
    "### Comment survivre au naufrage du *Titanic*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2635e02-c263-442b-a353-79e88481b1cc",
   "metadata": {},
   "source": [
    "Émettons l’hypothèse qu’être riche nous aurait fourni plus de chances pour survivre au naufrage du *Titanic*. Mais comment s’en assurer ? Mobilisons [un jeu de données](./data/titanic.csv) qui fournit quelques informations sur les passagers du fameux paquebot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163872e7-9175-4b77-9d49-7a79f363737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/titanic.csv')\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730adf1-7e43-4f85-9b30-3e9907181558",
   "metadata": {},
   "source": [
    "Retenons les variables `Pclass` et `Survived`, la première indiquant la classe de transport (1e, 2e ou 3e classe) et la seconde nous apprenant si la personne a survécu ou non (1 ou 0) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2bfd0-cfa0-46f5-bd1a-24e0e3097097",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[[\"Survived\", \"Pclass\"]]\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e6c14-b738-4130-ab39-fd292a51d653",
   "metadata": {},
   "source": [
    "Créons maintenant une table de contingence afin de savoir combien de passagers et passagères ont péri ou survécu en fonction de leurs conditions d’hébergement à bord :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d5666-6008-46e6-abc7-941a6e570e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(df.Pclass, df.Survived)\n",
    "\n",
    "display(contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056b6cd-3eb7-42c5-906f-fc3724a59ecb",
   "metadata": {},
   "source": [
    "Dans ce tableau, nous lisons par exemple que 80 personnes de la première classe ont péri contre 372 de la seconde classe. À titre informatif, notons qu’il est possible d’obtenir les sommes marginales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c55aa-9899-40e2-abd1-e41df8dbd79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Pclass, df.Survived, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531adef-f1d4-4c30-8c4c-c2242f213e8e",
   "metadata": {},
   "source": [
    "De là, nous devons calculer les valeurs théoriques attendues ($E_{ij}$) en cas d’indépendance des variables :\n",
    "\n",
    "$$\n",
    "E_{ij} = \\frac{ \\sum_{j=1}^{J}O_{ij} \\cdot \\sum_{i=1}^{I}O_{ij}}{N}\n",
    "$$\n",
    "\n",
    "|Pclass|0|1|\n",
    "|:-:|:-:|:-|\n",
    "|1|(216 * 549) / 891 = **133.09**|(216 * 342) / 891 = **82.91**|\n",
    "|2|(184 * 549) / 891 = **113.37**|(184 * 342) / 891 = **70.63**|\n",
    "|3|(491 * 549) / 891 = **302.54**|(491 * 342) / 891 = **188.46**|\n",
    "\n",
    "La matrice $E_{ij}$ peut s’obtenir directement avec Python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b2073-6211-4751-b73c-2b70644dde78",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = contingency.sum().sum()\n",
    "Oi = contingency.sum(axis=1).values\n",
    "Oj = contingency.sum(axis=0).values\n",
    "\n",
    "# reshape Oi\n",
    "Oi = Oi.reshape(contingency.shape[0], 1)\n",
    "\n",
    "Eij = (Oi * Oj) / N\n",
    "\n",
    "display(Eij)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd87a4-4a9b-48b7-9b4b-724b4b25a1de",
   "metadata": {},
   "source": [
    "Il ne reste plus qu’à calculer la valeur du $\\chi^2$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f5171-6b33-40df-a907-ebeca2f26b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_squared = (contingency.values - Eij) ** 2 / Eij\n",
    "\n",
    "display(chi_squared.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb70a0-80b3-4039-bd1d-7790f5e4d969",
   "metadata": {},
   "source": [
    "#### Interprétation avec la table de distribution du $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac497b2-8f95-4b09-9ecd-0faf4e9bb375",
   "metadata": {},
   "source": [
    "La [loi du $\\chi^2$](https://fr.wikipedia.org/wiki/Loi_du_%CF%87%C2%B2#Table_de_valeurs_des_quantiles) fournit des valeurs critiques pour chaque niveau de seuil $\\alpha$ avec $k$ degrés de liberté. Dans notre exemple, nous avons retenu un seuil de risque de 0,05 et le nombre de degrés de liberté est de $(3 - 1)(2 - 1) = 2$. La valeur critique donnée par la table est de 5,99. Notre résultat lui étant bien supérieur, nous pouvons rejeter $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619f273-1f15-4366-9dd1-b97860f31746",
   "metadata": {},
   "source": [
    "#### Interprétation avec la valeur-p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86352f-9c48-4083-b4a0-7423c6e2ee6a",
   "metadata": {},
   "source": [
    "Plus communément, l’interprétation d’un test statistique se fait avec la valeur-p qui dans notre exemple exprime la probabilité d’obtenir une valeur aussi extrême que celle observée. Si la valeur-p est inférieure au seuil de 0,05, nous pouvons rejeter l’hypothèse nulle.\n",
    "\n",
    "La méthode `chi2.sf()` de *Scipy* permet de calculer la valeur-p à partir d’un $\\chi^2$ et du nombre de degrés de libertés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b54567-974a-4c40-abc5-6d57473e85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "display(chi2.sf(chi_squared.sum(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902dbc99-a951-44af-81cc-d01a96e2587a",
   "metadata": {},
   "source": [
    "À noter l’existence d’une fonction `chi2_contingency()` qui ressort toutes les mesures désirées à partir d’un tableau de contingence sans les sommes marginales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d3f26-23b2-462a-aacd-b25341ee52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2, pvalue, degrees, expected = chi2_contingency(contingency)\n",
    "\n",
    "print(\n",
    "    f\"Valeur du khi-deux : {chi2:.4f}\",\n",
    "    f\"Probabilité du khi-deux (valeur-p) : {pvalue:.4f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d2599-631e-445d-b2a9-b3fb65329120",
   "metadata": {},
   "source": [
    "## Test de la distance entre deux vocabulaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605faa55-cc6b-4255-b12e-ff06a3bb7bbc",
   "metadata": {},
   "source": [
    "Formulons une nouvelle hypothèse selon laquelle un texte anonyme n’est pas de la main d’un auteur particulier. Pour la tester, nous envisageons de calculer la distance entre la fréquence des occurrences des mots dans le texte anonyme et celle observée dans le corpus de l’auteur. Si à la fin du test la valeur-p est inférieure au seuil de 5 %, nous présumons que notre hypothèse est fausse et retenons l’hypothèse alternative.\n",
    "\n",
    "La méthode consiste à :\n",
    "\n",
    "1. obtenir les vocabulaires du texte anonyme et du corpus de l’auteur ;\n",
    "2. les combiner afin d’obtenir un vocabulaire complet ;\n",
    "3. sélectionner les $n$ mots les plus fréquents du corpus combiné ;\n",
    "4. calculer les valeurs théoriques ($E_{ij}$) dans chacun des deux corpus ;\n",
    "5. calculer la distance avec les valeurs empiriques.\n",
    "\n",
    "Avant de commencer, chargeons toutes les bibliothèques logicielles nécessaires ainsi que les textes à comparer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec5365-de11-4afc-8217-30860e450cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "corpus = [\n",
    "    \"Le petit chat boit du lait.\",\n",
    "    \"Le petit chien boit de l’eau.\",\n",
    "    \"La vache boit de l’eau mais ne boit pas de lait.\"\n",
    "]\n",
    "\n",
    "anonym = \"Le petit oiseau boit de l’eau.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5cde16-563e-48df-a0a0-e5f252f7033f",
   "metadata": {},
   "source": [
    "### Étape 1 : obtenir les vocabulaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a26abd-3c82-4727-b74d-e812e8cf13b0",
   "metadata": {},
   "source": [
    "La réalisation de cette étape consiste à appliquer toutes les opérations mises en jeu dans une tâche de sac de mots. Nous nous contentons ici d’une banale tokenisation afin d’obtenir au final deux matrices d’occurrences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23614eb7-2323-4979-9727-cb3619647f7f",
   "metadata": {},
   "source": [
    "#### La matrice des occurrences du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ab37a-7958-473e-99d1-00e87af34de8",
   "metadata": {},
   "source": [
    "La segmentation est effectuée pour chaque texte de la variable `corpus` en filtrant sur les mots de deux caractères et moins :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b0497-c199-467a-966d-a411f23599a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_corpus = [\n",
    "    word.lower()\n",
    "    for sent in corpus\n",
    "    for word in tokenizer.tokenize(sent)\n",
    "    if len(word) > 2\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafcd3b4-5144-4c74-acc1-6ce78e554e27",
   "metadata": {},
   "source": [
    "Grâce à un objet de type `Counter()`, il est maintenant aisé d’obtenir les fréquences d’apparition des mots dans le corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1254270-d641-4b8c-9639-63a7954bd7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences_corpus = Counter(words_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ffa32-0da5-4a8c-8e87-f3dc73592c09",
   "metadata": {},
   "source": [
    "#### La matrice d’occurrences du texte anonyme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda6d54-5e44-4989-8b9b-8aab2b76f6c4",
   "metadata": {},
   "source": [
    "Répétons l’opération pour le texte anonyme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125ecaa-b52e-4208-bd56-372bc29ce3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences_anonym = Counter([\n",
    "    word.lower()\n",
    "    for word in tokenizer.tokenize(anonym)\n",
    "    if len(word) > 2\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0458f5c-04d7-4dc4-a0f3-5ba5bf95a406",
   "metadata": {},
   "source": [
    "### Étape 2 : combiner les deux vocabulaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cabd7e3-f5a6-4787-8f75-c0d8c0670235",
   "metadata": {},
   "source": [
    "Une opération triviale qui consiste à fusionner les deux objets de type `Counter` en un troisième :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2685b0-4a69-4063-b615-0df438725b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences_all = occurrences_corpus + occurrences_anonym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa1100-0442-45ce-8a76-0c698b350aa8",
   "metadata": {},
   "source": [
    "Regardons un aperçu du résultat dans un *data frame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd2b4f-d0b6-4c72-a345-8394789116cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=occurrences_all.values(),\n",
    "    index=occurrences_all.keys(),\n",
    "    columns=[\"All\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
